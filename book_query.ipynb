{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('./books', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2289"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 2000, chunk_overlap = 200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='(2008): 740–53.\\nsettle our differences\\n: Barbara Mellers, Ralph Hertwig, and Daniel\\nKahneman, “Do Frequency Representations Eliminate Conjunction\\nEffects? An Exercise in Adversarial Collaboration,” \\nPsychological\\nScience\\n 12 (2001): 269–75.\\n16: Causes Trump Statistics\\ncorrect answer is 41%\\n: Applying Bayes’s rule in odds form, the prior odds\\nare the odds for the Blue cab from the base rate, and the likelihood ratio is\\nthe ratio of the probability of the witness saying the cab is Blue if it is Blue,\\ndivided by the probability of the witness saying the cab is Blue if it is\\nGreen: posterior odds = (.15/.85) × (.80/.20) = .706. The odds are the ratio\\nof the probability that the cab is Blue, divided by the probability that the cab\\nis Green. To obtain the probability that the cab is Blue, we compute:\\nProbability (Blue) = .706/1. 706 = .41. The probability that the cab is Blue\\nis 41%.\\nnot too far from the Bayesian\\n: Amos Tversky and Daniel Kahneman,\\n“Causal Schemas in Judgments Under Uncertainty,” in \\nProgress in Social\\nPsychology\\n, ed. Morris Fishbein (Hillsdale, NJ: Erlbaum, 1980), 49–72.\\nUniversity of Michigan\\n: Richard E. Nisbett and Eugene Borgida,\\n“Attribution and the Psychology of Prediction,” \\nJournal of Personality and\\nSocial Psychology\\n 32 (1975): 932–43.\\nrelieved of responsibility\\n: John M. Darley and Bibb Latane, “Bystander\\nIntervention in Emergencies: Diffusion of Responsibility,” \\nJournal of\\nPersonality and Social Psychology\\n 8 (1968): 377–83.\\n17: Regression to the Mean\\nhelp of the most brilliant statisticians\\n: Michael Bulmer, \\nFrancis Galton:\\nPioneer of Heredity and Biometry\\n (Baltimore: Johns Hopkins University\\nPress, 2003).\\nstandard scores: Researchers transform each original score into a\\nstandard score by subtracting the mean and dividing the result by the\\nstandard deviation. Standard scores have a mean of zero and a standard\\ndeviation of 1, can be compared across variables (especially when the', metadata={'source': 'books\\\\Thinking-Fast-and-Slow.pdf', 'page': 472})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Llama2 Prompting\\llama_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "f:\\Llama2 Prompting\\llama_venv\\Lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "#pip install bitsandbytes accelerate transformers\n",
    "#pip install -U FlagEmbedding\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en\"\n",
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "check = embeddings.embed_query(\"how are you?\")\n",
    "print(len(check))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pinecone-client\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "# PINECONE_ENV = os.environ.get('PINECONE_ENV')\n",
    "PINECONE_API_KEY = \"29215c49-3fa5-488d-86fb-64cbc6c98a8d\"\n",
    "PINECONE_ENV = \"us-west4-gcp-free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  \n",
    "    environment=PINECONE_ENV\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"source-embed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embed = Pinecone.from_texts ([t.page_content for t in docs], embeddings, index_name = index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you already have an index, you can load it like this\n",
    "\n",
    "#text_embed = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='would\\talways\\thave\\ta\\tbig\\tbelly\\tlaugh\\tabout\\tthe\\twhole\\tdebacle.\\tMost\\tnights\\nwe’d\\twind\\tup\\tat\\tsome\\tdive\\tbar,\\tgiddy,\\talmost\\tdelirious.\\tBefore\\tparting\\twe’d\\noften\\tplay\\ta\\tgame.\\tI’d\\tbring\\tout\\ta\\tstopwatch\\tand\\twe’d\\tsee\\thow\\tfast\\tWoodell\\ncould\\tfold\\tup\\this\\twheelchair\\tand\\tget\\tit\\tand\\thimself\\tinto\\this\\tcar.\\tAs\\ta\\tformer', metadata={}),\n",
       " Document(page_content='track\\tstar,\\the\\tloved\\tthe\\tchallenge\\tof\\ta\\tstopwatch,\\tof\\ttrying\\tto\\tbeat\\this\\npersonal\\tbest.\\t(His\\trecord\\twas\\tforty-four\\tseconds.)\\tWe\\tboth\\tcherished\\tthose\\nnights,\\tthe\\tsilliness,\\tthe\\tsense\\tof\\tshared\\tmission,\\tand\\twe\\tmutually\\tranked\\nthem\\tamong\\tthe\\tsolid\\tgold\\tmemories\\tof\\tour\\tyoung\\tlives.\\nWoodell\\tand\\tI\\twere\\tvery\\tdifferent,\\tand\\tyet\\tour\\tfriendship\\twas\\tbased\\ton\\ta\\nselfsame\\tapproach\\tto\\twork.\\tEach\\tof\\tus\\tfound\\tpleasure,\\twhenever\\tpossible,\\tin\\nfocusing\\ton\\tone\\tsmall\\ttask.\\tOne\\ttask,\\twe\\toften\\tsaid,\\tclears\\tthe\\tmind.\\tAnd\\neach\\tof\\tus\\trecognized\\tthat\\tthis\\tsmall\\ttask\\tof\\tfinding\\ta\\tbigger\\toffice\\tmeant\\twe\\nwere\\tsucceeding.\\tWe\\twere\\tmaking\\ta\\tgo\\tof\\tthis\\tthing\\tcalled\\tBlue\\tRibbon,\\nwhich\\tspoke\\tto\\ta\\tdeep\\tdesire,\\tin\\teach\\tof\\tus,\\tto\\twin.\\tOr\\tat\\tleast\\tnot\\tlose.\\nThough\\tneither\\tof\\tus\\twas\\tmuch\\tof\\ta\\ttalker,\\twe\\tbrought\\tout\\ta\\tchatty\\tstreak\\nin\\teach\\tother.\\tThose\\tnights\\twe\\tdiscussed\\teverything,\\topened\\tup\\tto\\teach\\nother\\twith\\tunusual\\tcandor.\\tWoodell\\ttold\\tme\\tin\\tdetail\\tabout\\this\\tinjury.\\tIf\\tI\\nwas\\tever\\ttempted\\tto\\ttake\\tmyself\\ttoo\\tse\\nriously,\\tWoodell’s\\tstory\\talways\\nreminded\\tme\\tthat\\tthings\\tcould\\tbe\\tworse.\\tAnd\\tthe\\tway\\the\\thandled\\thimself\\nwas\\ta\\tconstant,\\tbracing\\tlesson\\tin\\tthe\\tvirtue,\\tand\\tvalue,\\tof\\tgood\\tspirits.\\nHis\\tinjury\\twasn’t\\ttypical,\\the\\tsaid.\\tAnd\\tit\\twasn’t\\ttotal.\\tHe\\tstill\\thad\\tsome\\nfeeling,\\tstill\\thad\\thopes\\tof\\tmarrying,\\thaving\\ta\\tfamily.\\tHe\\talso\\thad\\thopes\\tof\\ta\\ncure.\\tHe\\twas\\ttaking\\tan\\texperimental\\tnew\\tdrug,\\twhich\\thad\\tshown\\tpromise\\tin\\nparaplegics.\\tTrouble\\twas,\\tit\\thad\\ta\\tgarlicky\\taroma.\\tSome\\tnights\\ton\\tour\\toffice-\\nhunting\\texpeditions\\tWoodell\\twould\\tsmell\\tlike\\tan\\told-school\\tpizzeria,\\tand\\tI’d\\nlet\\thim\\thear\\tabout\\tit.\\nI\\tasked\\tWoodell\\tif\\the\\twas—I\\thesitated,\\tfearing\\tI\\thad\\tno\\tright—\\nhappy\\n.\\tHe\\ngave\\tit\\tsome\\tthought.\\tYes,\\the\\tsaid.\\tHe\\twas.\\tHe\\tloved\\this\\twork.\\tHe\\tloved\\nBlue\\tRibbon,\\tthough\\the\\tsometimes\\tcringed\\tat\\tthe\\tirony.\\tA\\tman\\twho\\tcan’t\\nwalk\\tpeddling\\tshoes.\\nNot\\tsure\\twhat\\tto\\tsay\\tto\\tthis,\\tI\\tsaid\\tnothing.\\nOften\\tPenny\\tand\\tI\\twould\\thave\\tWoodell\\tover\\tto\\tthe\\tnew\\thouse\\tfor\\tdinner.\\nHe\\twas\\tlike\\tfamily,\\twe\\tloved\\thim,\\tbut\\twe\\talso\\tknew\\twe\\twere\\tfilling\\ta\\tvoid\\tin', metadata={}),\n",
       " Document(page_content='administration\\tfor\\thim.\\tThe\\twhole\\tthing\\tneeded\\treorganizing,\\tstreamlining,\\nand\\tthat\\twasn’t\\tthe\\tbest\\tuse\\tof\\tJohnson’s\\ttime\\tor\\tcreativity.\\tThat\\twas\\ta\\tjob\\ntailor-made\\tfor\\tsomeone\\tlike\\t.\\t.\\t.\\tWoodell.\\nNight\\tafter\\tnight,\\tduring\\tmy\\tsix-mile\\trun,\\tI’d\\twrestle\\twith\\tthis\\tsituation.\\tI\\nhad\\ttwo\\tguys\\tin\\tthe\\twrong\\tjobs,\\ton\\tthe\\twrong\\tcoasts,\\tand\\tneither\\tone\\twas\\ngoing\\tto\\tlike\\tthe\\tobvious\\tsolution.\\tEach\\tguy\\tloved\\twhere\\the\\tlived.\\tAnd\\teach\\nirritated\\tthe\\tother,\\tthough\\tthey\\tboth\\tdenied\\tit.\\tWhen\\tI’d\\tpromoted\\tWoodell', metadata={}),\n",
       " Document(page_content='Woodell\\tto\\tdo.\\tAt\\tpresent,\\the\\tsaid,\\tthe\\tpoor\\tguy\\twas\\tsitting\\taround\\this\\nparents’\\thouse\\tin\\ta\\twheelchair,\\tstaring\\tat\\tthe\\twalls.\\tWoodell\\thad\\tmade\\ntentative\\tinquiries\\tabout\\tbeing\\tBowerman’s\\tassistant\\tcoach,\\tbut\\tBowerman', metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"who is woodell?\"\n",
    "query_similar = text_embed.similarity_search(query,k= 4)\n",
    "query_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "import together\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from typing import Any, Dict, List, Mapping, Optional\n",
    "#pydantic model version>2 will not work with langchain. you should install a model version less than 2\n",
    "from pydantic import Extra, Field, root_validator\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "from langchain.utils import get_from_dict_or_env\n",
    "import re\n",
    "\n",
    "together.api_key = config(\"TOGETHER_API_KEY\")\n",
    "\n",
    "together.Models.start(\"togethercomputer/llama-2-70b-chat\")\n",
    "\n",
    "class TogetherLLM(LLM):\n",
    "    \"\"\"Together large language models.\"\"\"\n",
    "\n",
    "    model = \"togethercomputer/llama-2-70b-chat\"\n",
    "    \"\"\"model endpoint to use\"\"\"\n",
    "\n",
    "    together_api_key = config(\"TOGETHER_API_KEY\")\n",
    "    \"\"\"Together API key\"\"\"\n",
    "\n",
    "    temperature = 0.7\n",
    "    \"\"\"What sampling temperature to use.\"\"\"\n",
    "\n",
    "    max_tokens = 512\n",
    "    \"\"\"The maximum number of tokens to generate in the completion.\"\"\"\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.forbid\n",
    "\n",
    "    @root_validator()\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        \"\"\"Validate that the API key is set.\"\"\"\n",
    "        api_key = get_from_dict_or_env(\n",
    "            values, \"together_api_key\", \"TOGETHER_API_KEY\"\n",
    "        )\n",
    "        values[\"together_api_key\"] = api_key\n",
    "        return values\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        \"\"\"Return type of LLM.\"\"\"\n",
    "        return \"together\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        \"\"\"Call to Together endpoint.\"\"\"\n",
    "        together.api_key = self.together_api_key\n",
    "        output = together.Complete.create(prompt,\n",
    "                                          model=self.model,\n",
    "                                          max_tokens=self.max_tokens,\n",
    "                                          temperature=self.temperature,\n",
    "                                          )\n",
    "        text = output['output']['choices'][0]['text']\n",
    "        # Use regex substitution to remove newlines\n",
    "        #cleaned_text = re.sub(r\"\\n\", \"\", text)\n",
    "        return text\n",
    "\n",
    "tog_llm = TogetherLLM(\n",
    "    model= \"togethercomputer/llama-2-70b-chat\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1024)\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT ):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[INST]<<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \\n<</SYS>>\\n\\nCONTEXT:/n/n {context}/n\\nQuestion: {question}[/INST]\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_prompt = \"\"\"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \"\"\"\n",
    "instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
    "Question: {question}\"\"\"\n",
    "get_prompt(instruction, sys_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "my_template = get_prompt(instruction, sys_prompt)\n",
    "\n",
    "llama_prompt = PromptTemplate(\n",
    "    template=my_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\":llama_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import prompt\n",
    "# create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=tog_llm,\n",
    "                                       chain_type=\"stuff\",\n",
    "                                       retriever=text_embed.as_retriever(search_kwargs={\"k\": 5}),\n",
    "                                       chain_type_kwargs=chain_type_kwargs,\n",
    "                                       return_source_documents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## text clean up\n",
    "\n",
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Woodell is a friend of the narrator's who is a paraplegic. He is a former track star who was injured in a car accident and is now confined to a wheelchair. Despite his disability, Woodell is a positive and energetic person who is passionate about his work and enjoys spending time with the narrator and their mutual friends.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is woodell?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The author discussed Woodell in the book \"Shoe Dog\" by Phil Knight.\n"
     ]
    }
   ],
   "source": [
    "query = \"In which book the author discussed about woodell?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided context, it seems that Malcolm Gladwell's writing style and narrative voice have been widely praised for their engaging and thought-provoking qualities. Many of the reviewers mentioned that Gladwell's use of anecdotes and interviews to illustrate his theories on human potential and success is particularly effective in capturing the reader's attention and making complex ideas more accessible.\n",
      "\n",
      "In terms of structuring the book in the most engaging way, it's worth noting that Gladwell's books, including \"Outliers,\" are often praised for their clear and direct prose, which makes the reading experience both enjoyable and thought-provoking. The book's structure, which weaves together anecdotes, interviews, and scientific research, has been described as \"masterful\" and \"impeccable.\"\n",
      "\n",
      "Therefore, based on the provided context, it seems that Malcolm Gladwell's writing style and narrative voice are the most compelling, and his book \"Outliers\" is structured in the most engaging way.\n"
     ]
    }
   ],
   "source": [
    "query = \"Whose writing style and narrative voice did you find the most compelling? Who structured their book in the most engaging way?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The anecdotes in Malcolm Gladwell's books reveal intriguing habits and mindsets of great leaders. In \"Outliers,\" the story of the Beatles' rise to fame highlights the importance of dedication and practice in achieving success. The anecdote about the Beatles' performance at the Cavern Club, where they honed their craft and developed their unique sound, demonstrates the power of deliberate practice in achieving mastery. This anecdote reflects the leadership quality of persistence and commitment to excellence.\n",
      "\n",
      "Another anecdote in \"Outliers\" that reveals a key habit of successful leaders is the story of the Rothschild family's success in banking. The anecdote highlights the importance of taking calculated risks and being adaptable in response to changing circumstances. This anecdote reflects the leadership quality of being proactive and taking calculated risks to achieve success.\n",
      "\n",
      "In \"Blink,\" the anecdote about the psychologist Daniel Kahneman's work on cognitive biases highlights the importance of intuition in decision-making. This anecdote reflects the leadership quality of trusting one's instincts and making quick decisions based on gut feelings.\n",
      "\n",
      "Finally, in \"The Tipping Point,\" the anecdote about the rise of Hush Puppies shoes in the mid-1990s highlights the importance of understanding cultural trends and being able to capitalize on them. This anecdote reflects the leadership quality of being able to read and respond to changes in the cultural landscape.\n",
      "\n",
      "Overall, the anecdotes in Malcolm Gladwell's books reveal that successful leaders possess a combination of skills, habits, and mindsets that enable them to achieve success in their respective fields. These include persistence, adaptability, intuition, and the ability to read and respond to changes in the cultural landscape.\n"
     ]
    }
   ],
   "source": [
    "query = \"What anecdotes among the 4 books revealed the most intriguing habits or mindsets of great leaders? Which were most reflective of their leadership qualities?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
